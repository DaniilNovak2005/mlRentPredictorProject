{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba0b4162"
      },
      "source": [
        "# Task\n",
        "Create a program to read the file \"/content/amenity_analysis_results.csv\", filter out the 1% most expensive houses, one-hot encode the 'Appliance' column and all other string columns, train an XGBoost model to predict the 'Price' column, cross-evaluate the hyperparameters, and then show a list of the highest errors between predicted and actual rent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68e6e2c6"
      },
      "source": [
        "## Load data\n",
        "\n",
        "### Subtask:\n",
        "Load the data from the specified CSV file into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a97ee00a"
      },
      "source": [
        "**Reasoning**:\n",
        "Import pandas and load the CSV file into a DataFrame, then display the head and info.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "165c9edc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "df = pd.read_csv(\"/content/sample_data/floridaHomeDetailsV3.csv\",on_bad_lines='skip')\n",
        "\n",
        "df.head().to_csv(\"floridaHomeDetailsV3UnEncoded.csv\")\n",
        "\n",
        "# Function to extract zipcode from URL\n",
        "def extract_zipcode_from_url(url):\n",
        "    if isinstance(url, str):\n",
        "        try:\n",
        "            parts = url.split('/homedetails/')[1].split('/')\n",
        "            # Assuming the zipcode is the part before the _zpid\n",
        "            zip_part = parts[-2] if '-' in parts[-2] else parts[-1]\n",
        "            zipcode = zip_part.split('-')[0]\n",
        "            return zipcode\n",
        "        except:\n",
        "            return np.nan\n",
        "    return np.nan\n",
        "\n",
        "# Function to recalculate Average Rental Price\n",
        "def recalculate_average_rent(row):\n",
        "    times_rented = row['Times Rented']\n",
        "    last_rental_price = row['Last Rental Price']\n",
        "    average_time_on_market = row['Average Time on Market'] # Assuming this is the old average\n",
        "\n",
        "    # Check for conditions where calculation is not possible or would result in NaN\n",
        "    if pd.isna(times_rented) or times_rented < 2 or pd.isna(last_rental_price) or pd.isna(average_time_on_market):\n",
        "        return np.nan\n",
        "    else:\n",
        "        # Apply the formula: (Old Average * Times Rented - Last Rental Price) / (Times Rented - 1)\n",
        "        # Need to be careful if Times Rented is 1, as it would result in division by zero.\n",
        "        if times_rented - 1 == 0:\n",
        "            return np.nan # Avoid division by zero\n",
        "        else:\n",
        "            new_average = (average_time_on_market * times_rented - last_rental_price) / (times_rented - 1)\n",
        "            return new_average\n",
        "\n",
        "# Apply the function to fill missing zipcodes\n",
        "df['Zipcode'] = df.apply(\n",
        "    lambda row: extract_zipcode_from_url(row['URL']) if pd.isna(row['Zipcode']) else row['Zipcode'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Apply the function to recalculate Average Time on Market\n",
        "df['Average Time on Market'] = df.apply(recalculate_average_rent, axis=1)\n",
        "\n",
        "# Remove the top 10% of outliers based on 'Most Recent Time on Market'\n",
        "cutoff = df['Price'].quantile(0.95)\n",
        "print(f\"Using a cutoff of {cutoff:.2f} \")\n",
        "\n",
        "# Create a new DataFrame without the top 10% of outliers\n",
        "df = df[df['Price'] <= cutoff]\n",
        "\n",
        "display(df.head())\n",
        "display(df.info())\n",
        "display(df.columns)\n",
        "df['Price'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5007c97c"
      },
      "source": [
        "# Calculate 'Rent Estimate to actual Price' column\n",
        "df['Rent Estimate to actual Price'] = df['Rent Zestimate'] / df['Price']\n",
        "\n",
        "# Calculate 'price to area average by zipcode' column\n",
        "# First, calculate the average price per zipcode\n",
        "average_price_by_zipcode = df.groupby('Zipcode')['Price'].transform('mean')\n",
        "\n",
        "# Then, calculate the ratio of 'Price' to the average price by zipcode\n",
        "df['price to area average by zipcode'] = df['Price'] / average_price_by_zipcode\n",
        "\n",
        "# Function to extract the numerical month of the most recent 'Listed for rent' or 'Sold' event\n",
        "import json\n",
        "\n",
        "def get_most_recent_month(events_string):\n",
        "    try:\n",
        "        events = json.loads(events_string)\n",
        "        # Filter for 'Listed for rent' or 'Sold' events and sort by date\n",
        "        relevant_events = sorted([e for e in events if e['type'] in ['Listed for rent', 'Sold']],\n",
        "                                 key=lambda x: x['date'], reverse=True)\n",
        "        if relevant_events:\n",
        "            # Get the date of the most recent relevant event\n",
        "            most_recent_date_str = relevant_events[0]['date']\n",
        "            # Extract and return the numerical month\n",
        "            return pd.to_datetime(most_recent_date_str).month\n",
        "    except:\n",
        "        # Return NaN if there's an error parsing or no relevant events\n",
        "        return np.nan\n",
        "    return np.nan\n",
        "\n",
        "# Apply the function to create the 'month listed' column\n",
        "df['month listed'] = df['Events'].apply(get_most_recent_month)\n",
        "\n",
        "display(df[['Rent Estimate to actual Price', 'price to area average by zipcode', 'month listed']].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4362de2a"
      },
      "source": [
        "## Filter Data\n",
        "\n",
        "### Subtask:\n",
        "Filter out the 1% most expensive houses based on the 'Price' column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "348254a4"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the 99th percentile of the 'Price' column and filter the DataFrame to exclude houses with prices above this threshold. Display the head and info of the filtered DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca75bbb2"
      },
      "source": [
        "\n",
        "# Function to split and one-hot encode the 'Appliances' column\n",
        "def encode_appliances(df):\n",
        "    # Split the 'Appliances' string into a list of appliances, handling NaN values\n",
        "    appliances_list = df['Appliances'].str.split(', ').apply(lambda x: x if isinstance(x, list) else [])\n",
        "    # Get all unique appliances\n",
        "    all_appliances = sorted(list(set([item for sublist in appliances_list for item in sublist])))\n",
        "    # Create new columns for each appliance and fill with 1 if the appliance is present\n",
        "    for appliance in all_appliances:\n",
        "        df[f'Appliance_{appliance}'] = appliances_list.apply(lambda x: 1 if appliance in x else 0)\n",
        "    return df\n",
        "\n",
        "# Apply one-hot encoding to 'Appliances'\n",
        "df_filtered = encode_appliances(df)\n",
        "\n",
        "# Apply one-hot encoding to other string columns\n",
        "df_filtered = pd.get_dummies(df_filtered, columns=['Cooling', 'Heating', 'Parking', 'Laundry', 'Home Type'])\n",
        "\n",
        "display(df_filtered.head())\n",
        "display(df_filtered.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ab925be"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def fill_nan_with_median(df):\n",
        "    \"\"\"\n",
        "    Fills NaN values in a DataFrame with the median of each column using a manual loop.\n",
        "    If the median cannot be calculated for a column, the NaN values in that column will remain NaN.\n",
        "    \"\"\"\n",
        "    df_copy = df.copy()\n",
        "    for col in df_copy.columns:\n",
        "        try:\n",
        "            # Attempt to calculate the median. Use try-except to catch errors for non-numeric columns\n",
        "            median_val = df_copy[col].median()\n",
        "            if not pd.isna(median_val):\n",
        "                df_copy[col] = df_copy[col].fillna(median_val)\n",
        "        except:\n",
        "            # If median cannot be calculated (e.g., non-numeric column), leave NaN values as they are\n",
        "            pass # Do nothing, leave NaN values\n",
        "    return df_copy\n",
        "\n",
        "\n",
        "# Apply the custom NaN filling function\n",
        "df_filled = fill_nan_with_median(df_filtered.copy())\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "df_shuffled = df_filled.sample(frac=1, random_state=41).reset_index(drop=True)\n",
        "\n",
        "display(df_shuffled.head())\n",
        "display(df_shuffled.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXvcMA_w2wn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shuffled.head().to_csv(\"floridaHomeDataIncomeEncodedV2.csv\" ,index=False)"
      ],
      "metadata": {
        "id": "ChdaEDpx00TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b6ef390"
      },
      "source": [
        "## Train XGBoost Model\n",
        "\n",
        "### Subtask:\n",
        "Train an XGBoost model to predict the 'Price' column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b9dd0b4"
      },
      "source": [
        "**Reasoning**:\n",
        "Separate the features (X) and target variable (y), split the data into training and testing sets, and train an XGBoost Regressor model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "832c7f2a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "X = df_shuffled.drop(columns=['Price', 'Street Address', 'City', 'State', 'URL', 'Appliances', \"Image URLs\", \"Date Details Fetched\", \"Events\",\"Rent Estimate to actual Price\",\"price to area average by zipcode\"])\n",
        "y = df_shuffled['Price']\n",
        "\n",
        "df_shuffled.to_csv(\"testEncoded.csv\")\n",
        "\n",
        "# Select only numeric columns for training\n",
        "X = X.select_dtypes(include=np.number)\n",
        "\n",
        "# Replace infinite values with NaN and then fill NaN with the median\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_test.head().to_csv(\"testOutput.csv\")\n",
        "\n",
        "# Initialize and train the XGBoost Regressor model\n",
        "xgbr = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200, learning_rate=0.01, random_state=42)\n",
        "xgbr.fit(X_train, y_train)\n",
        "\n",
        "print(\"XGBoost model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60c8003a"
      },
      "source": [
        "## Cross-evaluate Hyperparameters and Evaluate Model\n",
        "\n",
        "### Subtask:\n",
        "Cross-evaluate the hyperparameters of the trained XGBoost model and calculate the R2 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dc6bab9"
      },
      "source": [
        "**Reasoning**:\n",
        "Use cross-validation to evaluate the model's performance across different subsets of the data and calculate the R2 score on the test set to assess the model's goodness of fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca57b379"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Cross-evaluate the model using cross-validation\n",
        "# Using R2 as the scoring metric\n",
        "scores = cross_val_score(xgbr, X_train, y_train, cv=10, scoring='r2')\n",
        "\n",
        "print(f\"Cross-validation R2 scores: {scores}\")\n",
        "print(f\"Mean cross-validation R2 score: {scores.mean()}\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = xgbr.predict(X_test)\n",
        "\n",
        "# Calculate the R2 score on the test set\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R2 score on the test set: {r2}\")\n",
        "\n",
        "scores = cross_val_score(xgbr, X_train, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
        "\n",
        "print(f\"Cross-validation MAE scores: {scores}\")\n",
        "print(f\"Mean cross-validation MAE score: {scores.mean()}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9ca989a"
      },
      "source": [
        "## Analyze Highest Errors\n",
        "\n",
        "### Subtask:\n",
        "Show a list of the highest errors between predicted and actual rent."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ptfVy6mMJLhl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYTtyd-ZBj_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cf3e54d"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the absolute errors between the predicted and actual prices, sort the results by error in descending order, and display the instances with the highest errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1691aee6"
      },
      "source": [
        "# Calculate the absolute errors\n",
        "errors = abs(y_test - y_pred)\n",
        "\n",
        "# Create a DataFrame to show actual price, predicted price, and error\n",
        "error_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Error': errors})\n",
        "\n",
        "# Get the original index from the test set\n",
        "error_df = error_df.join(df_shuffled['URL'], how='left')\n",
        "\n",
        "\n",
        "# Sort by error in descending order and display the top errors\n",
        "display(error_df.sort_values(by='Error', ascending=False).head())\n",
        "error_df.sort_values(by='Error', ascending=False).to_csv('error_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fea382b"
      },
      "source": [
        "%pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "511fae87"
      },
      "source": [
        "## SHAP Analysis\n",
        "\n",
        "### Subtask:\n",
        "Generate a SHAP summary plot to visualize feature importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e341d41"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the `shap` library to calculate SHAP values for the test set and generate a summary plot to show the impact of each feature on the model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bff79cb4"
      },
      "source": [
        "import shap\n",
        "\n",
        "# Create a SHAP explainer object\n",
        "explainer = shap.TreeExplainer(xgbr)\n",
        "\n",
        "# Calculate SHAP values for the test set\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Generate the SHAP summary plot\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "print(df_shuffled['Price'].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28e89cc"
      },
      "source": [
        "## Calculate MAE, MSE, and RMSE\n",
        "\n",
        "### Subtask:\n",
        "Calculate and display the Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE) of the model's predictions in one cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7e68119"
      },
      "source": [
        "**Reasoning**:\n",
        "Use `sklearn.metrics.mean_absolute_error`, `sklearn.metrics.mean_squared_error`, and `numpy.sqrt` to calculate MAE, MSE, and RMSE using the actual and predicted values and display the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f02b52ca"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Select only numeric columns from the shuffled DataFrame\n",
        "df_shuffled_numeric = df_shuffled.select_dtypes(include=np.number)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix_shuffled = df_shuffled_numeric.corr()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(18, 16))\n",
        "\n",
        "# Create the correlation heatmap\n",
        "sns.heatmap(correlation_matrix_shuffled, cmap='coolwarm', annot=False)\n",
        "plt.title('Correlation Heatmap of Numeric Features (Shuffled Data)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yNmFRiGwfhxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a scatter plot of actual vs. predicted values\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred)\n",
        "plt.title('Actual vs. Predicted Price')\n",
        "plt.xlabel('Actual Price')\n",
        "plt.ylabel('Predicted Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iWfurCaafj13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}